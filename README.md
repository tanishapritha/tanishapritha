<h1 align="center">Tanisha Pritha</h1>
<p align="center">
AI Engineer · LLM Systems · Retrieval · Agentic Workflows
</p>

<p align="center">
  <a href="https://www.linkedin.com/in/tanishapritha">LinkedIn</a> |
  <a href="https://twitter.com/tpritha03">Twitter / X</a>
</p>

---

## About Me
I build practical AI systems with a focus on LLM internals, retrieval workflows, and agent architectures.  
My work emphasizes minimalism, clarity, and debuggability—designing systems where every component is transparent and every failure mode can be understood.

---

## Tech Stack

### Languages
<p align="left">
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" width="45"/>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/javascript/javascript-original.svg" width="45"/>
</p>

### AI / ML
<p align="left">
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/pytorch/pytorch-original.svg" width="45"/>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/numpy/numpy-original.svg" width="45"/>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" width="45"/>
</p>

### LLM Stack
<p align="left">
  <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white"/>
  <img src="https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/ChromaDB-8A2BE2?style=for-the-badge"/>
</p>

### Frontend / Backend
<p align="left">
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/react/react-original.svg" width="45"/>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/nodejs/nodejs-original.svg" width="45"/>
</p>

### Infrastructure / Tools
<p align="left">
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/docker/docker-original.svg" width="55"/>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/googlecloud/googlecloud-original.svg" width="55"/>
</p>

---

## AgentFlow Engine
A lightweight agent workflow engine built from scratch, combining structured planning, memory, tool execution, and a fully transparent reasoning trace.  
Designed as a clean alternative to heavy agent frameworks—focused on determinism rather than opaque chains.

Key concepts include:
- Planning and task decomposition  
- Short-term and persistent memory  
- Structured tool invocation  
- Reasoning trace visualization (frontend)

The system is evolving toward more reliable execution guarantees and grounded, context-aware planning.

---

## Local RAG (Chroma Edition)
A compact, fully local retrieval pipeline designed to remain minimal and easy to extend.  
Every component—chunking, embedding, indexing, and retrieval—is intentionally simple enough to inspect and reason about.

Includes:
- Semantic chunking  
- Configurable embedding backends  
- Chroma-based similarity search  
- Clean retrieval interface  

Built to avoid the complexity of oversized RAG stacks.

---

## Attention Mechanism → TinyGPT
A ground-up reconstruction of transformer fundamentals aimed at building a minimal GPT-style model.

Completed components:
- Scaled dot-product attention (NumPy + PyTorch)  
- Modular attention blocks with diagnostics for numerical stability  

Next milestones:
- Multi-head attention  
- Feed-forward network  
- LayerNorm  
- Assembly of a TinyGPT architecture  

This work strengthens my understanding of LLM behavior and model internals.

---

<p align="center">
If you're working on LLM systems, agents, or retrieval—and value thoughtful engineering—I'd be happy to connect.
</p>
